<!doctype html>
<html>

<head>

  <title>
    
      What makes a better score distribution? | statsandstuff
    
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/syntax.css">
  <!-- Use Atom -->
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="statsandstuff" />
  <!-- Use RSS-2.0 -->
  <!--<link href="/rss-feed.xml" type="application/rss+xml" rel="alternate" title="statsandstuff | a blog on statistics and machine learning"/>
  //-->

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-135466463-1', 'auto');
  ga('send', 'pageview');
</script>


<meta name="author" content="Scott Roy"/>  
<meta property="og:locale" content="en_US">
<meta property="og:description" content="Suppose I train two binary classifiers on some data, and after examining the score distributions of each, I see the results below. Which score distribution is better? (And by extension,...">
<meta property="description" content="Suppose I train two binary classifiers on some data, and after examining the score distributions of each, I see the results below. Which score distribution is better? (And by extension,...">
<meta property="og:title" content="What makes a better score distribution?">
<meta property="og:site_name" content="statsandstuff">
<meta property="og:type" content="article">
<meta property="og:url" content="http://localhost:4000/what-makes-a-better-score-distribution.html">
<meta property="og:image:url" content="http://localhost:4000/assets/img/mapped_scores.png">
<meta property="og:image:secure_url" content="http://localhost:4000/assets/img/mapped_scores.png">
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />



</head>


<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="/">statsandstuff</a>
    <small class="masthead-subtitle">a blog on statistics and machine learning</small>
    <div class="menu">
  <nav class="menu-content">
    
      <a href="/menu/about.html">About</a>
    
      <a href="/menu/writing.html">Writing</a>
    
      <a href="/menu/contact.html">Contact</a>
    
  </nav>
  <nav class="social-icons">
    
  
  
    <a href="https://www.github.com/scottroy" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/scott-roy/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:scott.michael.roy@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  </nav>
</div>

  </h3>
</header>


    <div class="post-container">
      <h1>
  What makes a better score distribution?
</h1>


  <img src="/assets/img/mapped_scores.png">


<p>Suppose I train two binary classifiers on some data, and after examining the score distributions of each, I see the results below.  Which score distribution is better?  (And by extension, which classifier is better?)</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/img/raw_scores_nolines.png" alt="" /></td>
      <td><img src="/assets/img/mapped_scores.png" alt="" /></td>
    </tr>
  </tbody>
</table>

<p>A naive answer is that the bimodal distribution on the right is better because it “discriminates between the positive and negative classes.”  But this is wrong.  In fact, the above two score distributions are actually equivalent.</p>

<h2 id="introduction">Introduction</h2>
<p>We form a classifier from a score distribution by thresholding it at some value <script type="math/tex">t</script>, and label an input as positive or negative depending on if its score is above or below <script type="math/tex">t</script>.  For a given classifer metric <script type="math/tex">M</script> (such as accuracy or a problem specific metric), let <script type="math/tex">M_t</script> denote the value of the metric when we threshold at <script type="math/tex">t</script>. The best classifier obtainable from the score distribution (with respect to the metric <script type="math/tex">M</script>) has metric value <script type="math/tex">M^* = \max_{t} M_t</script>.  (Notice that precision isn’t a metric to optimize over a score distribution because the precision is 1 if the threshold is sufficiently high.  Instead we optimize something like precision at a given recall in which <script type="math/tex">M = \text{precision} \cdot 1_{\text{recall} \geq a}</script> for some acceptable recall <script type="math/tex">a</script>.)</p>

<p>Score distribution shape is very malleable, and we can <em>artificially</em> change the shape of a score distribution without altering key metrics.
This is achieved by applying an increasing function to the scores that expands and contracts different parts of the distribution.  The reparametrization preserves score order, and therefore does not alter the AUC or many <script type="math/tex">M^*</script> metrics (e.g., maximum accuracy or maximum recall at a given precision).  It does, however, change how well the scores are calibrated.</p>

<h2 id="making-scores-look-bimodal">Making scores look bimodal</h2>

<p>We walk through an example to illustrate how flexible the shape of a score distribution is.  In particular, we’ll make a Guassian score distribution look bimodal.  The data is a set of observations, each with a model score, a true score, and a label.  The true score is the actual probability that the label is positive and was used to simulate the labels.  The model score is a random perturbation of the true score.  (The code snippet below shows precisely how these three were defined.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span> <span class="o">=</span> <span class="mi">1000000</span>

<span class="n">truncate</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">true_scores</span> <span class="o">=</span> <span class="n">truncate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.14</span><span class="p">))</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">true_probs</span><span class="p">)</span>

<span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">truncate</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">true_probs</span> <span class="o">+</span> <span class="n">e</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.25</span><span class="p">)</span>
</code></pre></div></div>

<p>The distribution of model scores and true scores is plotted below.  Both distributions are bell-shaped, but the model scores are narrower.  If we calibrate the model scores, they will disperse to look more like the true scores.</p>

<p><img src="/assets/img/model_true_scores.png" alt="" /></p>

<h3 id="constructing-a-mapping">Constructing a mapping</h3>
<p>We want an increasing function that maps the original model score distribution onto a specified target distribution, e.g., the bimodal distribution below.</p>

<p><img src="/assets/img/target_scores_nolines.png" alt="" /></p>

<p>Constructing such a function is fairly straightforward.  The basic procedure is outlined next.</p>

<ol>
  <li>
    <p>Divide the target distribution into <script type="math/tex">n</script> equally spaced buckets <script type="math/tex">[a_0, a_1], (a_1, a_2], \ldots, (a_{n-1}, a_n]</script> and compute the probability mass of each.  Let <script type="math/tex">p_1, p_2, \ldots, p_n</script> denote these masses.  An illustration with <script type="math/tex">n = 5</script> is shown below. <img src="/assets/img/target_scores.png" alt="" /></p>
  </li>
  <li>Divide the original distribution into <script type="math/tex">n</script> buckets <script type="math/tex">[b_0, b_1], (b_1, b_2], \ldots, (b_{n-1}, b_n]</script> so that the probability mass of the <script type="math/tex">j</script>th bucket is <script type="math/tex">p_j</script>.  The buckets will not (necessarily) be equally spaced.  This is depicted below. <img src="/assets/img/raw_scores.png" alt="" /></li>
  <li>Define an increasing function <script type="math/tex">f</script> that scales and shifts the <script type="math/tex">j</script>th bucket of the original distribution onto the <script type="math/tex">j</script>th bucket of the target distribution (both of which have the same mass).  This function maps the original distribution onto the target distribution.  Explicitly the function is</li>
</ol>

<script type="math/tex; mode=display">f(x) = \left( \frac{a_{j_x} - a_{j_x-1}}{b_{j_x} - b_{j_x-1}} \right) (x - b_{j_x-1}) + a_{j_x - 1} \text{ where } x \in (b_{j_x-1}, b_{j_x}].</script>

<p>The Python function below performs the above procedure.  It takes a sample of original scores, a sample of target scores, and the number of buckets <script type="math/tex">n</script> as input and returns an increasing function that maps the original scores onto the target scores.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_mapping</span><span class="p">(</span><span class="n">scores_original</span><span class="p">,</span> <span class="n">scores_target</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    
    <span class="c1"># Group target scores into equally spaced bins
</span>    <span class="c1"># and compute the amount of data in each bin
</span>    <span class="n">n_target</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_target</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">target</span><span class="p">[</span><span class="s">"Score"</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores_target</span>
    <span class="n">target</span><span class="p">[</span><span class="s">"ScoreBinned"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">cut</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="s">"Score"</span><span class="p">],</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"ScoreBinned"</span><span class="p">).</span><span class="n">agg</span><span class="p">(</span><span class="s">"count"</span><span class="p">).</span><span class="n">values</span> <span class="o">/</span> <span class="n">n_target</span>
    
    <span class="c1"># Compute boundaries b for original scores that map onto target bins
</span>    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">scores_original</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="n">b</span><span class="p">])</span>
    
    <span class="c1"># In pratice the last element of b will be near 1
</span>    <span class="c1"># We ensure it is exactly 1 so that the mapping function is defined on [0, 1]
</span>    <span class="n">b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    
    <span class="c1"># Define mapping function
</span>    <span class="k">def</span> <span class="nf">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">q2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.001</span><span class="p">)</span> <span class="c1"># Prevent divide by 0
</span>                
                <span class="k">return</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">q1</span> <span class="o">/</span> <span class="n">q2</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
            
        <span class="k">return</span> <span class="mf">1.0</span>
    
    <span class="k">return</span> <span class="n">mapping</span>
</code></pre></div></div>

<p>The mapping (with <script type="math/tex">n = 50</script>) that transforms the original Gaussian distribution into the bimodal target distribution is plotted below.</p>

<p><img src="/assets/img/mapper.png" alt="" /></p>

<p>If we apply this mapping function to the original scores, we get the following distribution of mapped scores.  (It looks like a replot of the target distribution, but there are slight differences between the two histograms in the valley between the peaks.)</p>

<p><img src="/assets/img/mapped_scores.png" alt="" /></p>

<p>The mapped bimodal distribution has the same AUC, precision at a given recall, and recall at a given precision as the original distribution.  Even so, it would be very silly to prefer the bimodal distribution over the Gaussian one because we artificially created it.</p>

<h2 id="what-happened-to-the-calibration">What happened to the calibration?</h2>
<p>The better bimodal shape is the result of worse calibration.  The calibration of the original scores is plotted on the left below, and the calibration of the mapped scores is plotted on the right.  Although the mapped scores have OK calibration, the original scores have better calibration.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/img/raw_scores_cali.png" alt="" /></td>
      <td><img src="/assets/img/mapped_scores_cali.png" alt="" /></td>
    </tr>
  </tbody>
</table>

<p>We can fix the calibration in both the original and mapped scores by applying an isotonic regression (which preserves ordering).  Both distributions have the same shape after being calibrated (plotted below).  The original scores become more spread out after calibration, and the bimodal shape of the mapped scores disappears.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/img/iso_scores.png" alt="" /></td>
      <td><img src="/assets/img/iso_cali.png" alt="" /></td>
    </tr>
  </tbody>
</table>

<h2 id="final-thoughts">Final thoughts</h2>
<p>In the example in this post, <em>we</em> artificially created the “better” score distribution shape.  But an ML algorithm can similarly create a better shape by not calibrating well, and this should be checked before claiming an algorithm gives a superior shape.  Even then, it perhaps better to show that one algorithm is better than another with respect to important problem metrics rather than with respect to a subjective notion of good score distribution shape.</p>


<span class="post-date">
  Written on
  
  September
  29th,
  2019
  by
  
    Scott Roy
  
</span>

<div class="post-date">Feel free to share!</div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=What makes a better score distribution?&amp;url=/what-makes-a-better-score-distribution.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=/what-makes-a-better-score-distribution.html&amp;title=What makes a better score distribution?" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
    <a href="https://plus.google.com/share?url=/what-makes-a-better-score-distribution.html" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
  </div>
</div>


<div class="related">
  <h1 >You may also enjoy:</h1>
  
  <ul class="related-posts">
    
      
        
        
      
    
      
        
        
      
    
      
        
        
      
        
          <li>
            <h3>
              <a href="/calibration-in-logistic-regression-and-other-generalized-linear-models.html">
                Calibration in logistic regression and other generalized linear models
                <!--<img src="http://localhost:4000/images/">-->
                <!--<small>August 21, 2018</small>-->
              </a>
            </h3>
          </li>
          
        
      
    
      
        
        
      
        
          <li>
            <h3>
              <a href="/ROC-space-and-AUC.html">
                ROC space and AUC
                <!--<img src="http://localhost:4000/images/">-->
                <!--<small>April 29, 2018</small>-->
              </a>
            </h3>
          </li>
          
        
      
    
  </ul>
</div>




    </div>

    <footer class="footer">
  
  
  
    <a href="https://www.github.com/scottroy" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/scott-roy/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:scott.michael.roy@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  <div class="post-date"><a href="/menu/about.html">statsandstuff | a blog on statistics and machine learning by Scott Roy</a></div>
</footer>

  </div>

</body>
</html>
