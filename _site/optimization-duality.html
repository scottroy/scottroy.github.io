<!doctype html>
<html>

<head>

  <title>
    
      Optimization and duality | statsandstuff
    
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/syntax.css">
  <!-- Use Atom -->
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="statsandstuff" />
  <!-- Use RSS-2.0 -->
  <!--<link href="/rss-feed.xml" type="application/rss+xml" rel="alternate" title="statsandstuff | a blog on statistics and machine learning"/>
  //-->

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-135466463-1', 'auto');
  ga('send', 'pageview');
</script>


<meta name="author" content="Scott Roy"/>  
<meta property="og:locale" content="en_US">
<meta property="og:description" content="Introduction Consider the optimization problem where the function defines constraints. Constraints can also be built into the set . The Lagrangian The Lagrangian is defined as In the Lagrangian, the...">
<meta property="description" content="Introduction Consider the optimization problem where the function defines constraints. Constraints can also be built into the set . The Lagrangian The Lagrangian is defined as In the Lagrangian, the...">
<meta property="og:title" content="Optimization and duality">
<meta property="og:site_name" content="statsandstuff">
<meta property="og:type" content="article">
<meta property="og:url" content="http://localhost:4000/optimization-duality.html">
<meta property="og:image:url" content="http://localhost:4000/assets/img/convex-conjugate.png">
<meta property="og:image:secure_url" content="http://localhost:4000/assets/img/convex-conjugate.png">
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />



</head>


<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="/">statsandstuff</a>
    <small class="masthead-subtitle">a blog on statistics and machine learning</small>
    <div class="menu">
  <nav class="menu-content">
    
      <a href="/menu/about.html">About</a>
    
      <a href="/menu/writing.html">Writing</a>
    
      <a href="/menu/contact.html">Contact</a>
    
  </nav>
  <nav class="social-icons">
    
  
  
    <a href="https://www.github.com/scottroy" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/scott-roy/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:scott.michael.roy@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  </nav>
</div>

  </h3>
</header>


    <div class="post-container">
      <h1>
  Optimization and duality
</h1>


  <img src="/assets/img/convex-conjugate.png">


<h2 id="introduction">Introduction</h2>

<p>Consider the optimization problem</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\inf_{x \in E} &\quad f(x) \\
\text{subject to} &\quad g(x) \leq 0,
\end{aligned} %]]></script>

<p>where the function <script type="math/tex">g: \mathbb{R}^n \to \mathbb{R^p}</script> defines <script type="math/tex">p</script> constraints.  Constraints can also be built into the set <script type="math/tex">E \subseteq \mathbb{R}^n</script>.</p>

<h3 id="the-lagrangian">The Lagrangian</h3>
<p>The Lagrangian is defined as</p>

<script type="math/tex; mode=display">L(x, \lambda) = f(x) + \lambda^T g(x) = f(x) + \sum_{i=1}^p \lambda_i g_i(x).</script>

<p>In the Lagrangian, the “hard” constraints <script type="math/tex">g_i(x) \leq 0, \ 1 \leq i \leq p,</script> in the optimization problem are replaced with “soft” penalties that can be violated, but for a cost; cost <script type="math/tex">\lambda_i</script> is incurred per unit violation of the <script type="math/tex">i</script>th constraint (and credit given per unit “under budget”).  A natural question is if there are “prices” <script type="math/tex">\lambda</script> for which</p>

<script type="math/tex; mode=display">\Pi(\lambda) := \inf_{x \in E} L(x, \lambda) = \inf_{x \in E} f(x) + \lambda^T g(x)</script>

<p>has the same solution set as the original problem?  This is not always the case, as the figure below illustrates.  In the figure, the curve <script type="math/tex">v(t) = \inf \{ f(x) : g(x) \leq t, x \in E \}</script> is plotted, which we assume is the boundary of the region <script type="math/tex">A = \{ (g(x), f(x)) : x \in E \}</script>.  The problem that defines <script type="math/tex">\Pi(\lambda)</script> can be viewed as maximization of the linear functional <script type="math/tex">(g, f) \mapsto (-\lambda, -1)^T (g,f)</script> over <script type="math/tex">A</script>.  The original problem corresponds to the point <script type="math/tex">(0, v(0))</script>, which cannot be obtained by maximizing a linear functional (note that the functional corresponding to the tangent at <script type="math/tex">(0, v(0))</script> is maximized at the red dot).</p>

<p><img src="/assets/img/scalarization.png" alt="" /></p>

<h3 id="primal-and-dual-problems">Primal and dual problems</h3>
<p>The connection between the original (primal) optimization problem and the  Lagrangian is given by</p>

<script type="math/tex; mode=display">p^* = \inf_{x \in E} \sup_{\lambda \in \mathbb{R}^n_+} L(x, \lambda),</script>

<p>where <script type="math/tex">p^*</script> is the primal optimal value.  This is easy to see by noting that</p>

<script type="math/tex; mode=display">% <![CDATA[
P(x) := \sup_{\lambda \in \mathbb{R}^p_+} L(x, \lambda) = \left\{ \begin{matrix} f(x) &\quad \text{if } g(x) \leq 0 \\ \infty &\quad \text{otherwise} \end{matrix} \right. . %]]></script>

<p>It is natural to consider the <em>dual problem</em> in which the order of the inf and sup are reversed:</p>

<script type="math/tex; mode=display">d^* := \sup_{\lambda \in \mathbb{R}^p_+} \inf_{x \in E}  L(x, \lambda).</script>

<p>The function <script type="math/tex">\Pi(\lambda) = \inf_{x \in E}  L(x, \lambda)</script> is called the Lagrangian dual function.</p>

<p>The minimax inequality implies <em>weak duality</em></p>

<script type="math/tex; mode=display">d^* = \sup_{\lambda \in \mathbb{R}^p_+} \Pi(\lambda) = \sup_{\lambda \in \mathbb{R}^p_+} \inf_{x \in E}  L(x, \lambda) \leq \inf_{x \in E} \sup_{\lambda \in \mathbb{R}^n_+} L(x, \lambda) = \inf_{x \in E} P(x) = p^*.</script>

<h2 id="the-minimax-inequality-and-saddle-points">The minimax inequality and saddle points</h2>

<p>The minimax inequality is</p>

<script type="math/tex; mode=display">\sup_{y \in Y} \inf_{x \in X} f(x, y) \leq \inf_{x \in X} \sup_{y \in Y} f(x, y)</script>

<p>and holds for any function <script type="math/tex">f</script> and any sets <script type="math/tex">X</script> and <script type="math/tex">Y</script>.  To derive the inequality, start with</p>

<script type="math/tex; mode=display">f(x, y) \leq \sup_{y \in Y} f(x,y),</script>

<p>then take an infimum on both sides</p>

<script type="math/tex; mode=display">\inf_{x \in X} f(x, y) \leq \inf_{x \in X} \sup_{y \in Y} f(x,y),</script>

<p>and finish with a supremum over the left side</p>

<script type="math/tex; mode=display">\sup_{y \in Y} \inf_{x \in X} f(x, y) \leq \inf_{x \in X} \sup_{y \in Y} f(x,y).</script>

<p>To illustrate the inequality in a simple setting, consider the discrete function <script type="math/tex">f(i,j)</script> whose values are enumerated in in the matrix below (<script type="math/tex">f(1,1) = 1</script>, <script type="math/tex">f(1,2) = 2</script>, <script type="math/tex">f(2,1) = 3</script>, and <script type="math/tex">f(2,2)=1</script>).</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{matrix} \begin{bmatrix} 1 & 2 \\ 3 & 1 \end{bmatrix} & \begin{matrix} \color{green}{2} \\ \color{green}{3} \end{matrix} \\ \begin{matrix} \color{red}{1} & \color{red}{1} \end{matrix} & \end{matrix} %]]></script>

<p>The minimax inequality says that the largest column min (1) is no more than the smallest row max (2).  (The column mins are shown in red below the matrix, and the row maxes are shown in green to the right of the matrix.)  This simple example shows that equality does not always hold.</p>

<h3 id="equality-and-saddle-points">Equality and saddle points</h3>
<p>Equality holding in the minimax inequality is closely related to the existence of saddle points of <script type="math/tex">f</script>.  A <em>saddle point</em> <script type="math/tex">(\bar{x}, \bar{y})</script> satifies</p>

<script type="math/tex; mode=display">f(\bar{x}, y) \leq f(\bar{x}, \bar{y}) \leq f(x, \bar{y})</script>

<p>for all <script type="math/tex">x \in X</script> and <script type="math/tex">y \in Y</script>.  A saddle point implies equality holds in minimax:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} 
\sup_{y \in Y} \inf_{x \in X} f(x,y) &\geq \inf_{x \in X} f(x, \bar{y}) \\
&\geq f(\bar{x}, \bar{y}) \\
&\geq \sup_{y \in Y} f(\bar{x}, y) \\
&\geq \inf_{x \in X} \sup_{y \in Y} f(x, y).
\end{aligned} %]]></script>

<p>In the discrete setting, a saddle point is an entry that is the largest in its row and the smallest in its column.  For example, 2 is a saddle point in the matrix below because it is the biggest value in its row and the smallest value in its column (and minimax equality holds).</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{matrix} \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} & \begin{matrix} \color{green}{2} \\ \color{green}{4} \end{matrix} \\ \begin{matrix} \color{red}{1} & \color{red}{2} \end{matrix} & \end{matrix} %]]></script>

<p>Since a saddle point implies equality in minimax, it is natural to wonder the converse: if equality holds, does <script type="math/tex">f</script> have a saddle point?  This is true as long as the optimal values are <em>attained</em>.  Suppose <script type="math/tex">\bar{x} \in X</script> is optimal in that</p>

<script type="math/tex; mode=display">\sup_{y \in Y} f(\bar{x}, y) = \inf_{x \in X} \sup_{y \in Y} f(x, y).</script>

<p>and <script type="math/tex">\bar{y} \in Y</script> is optimal in that</p>

<script type="math/tex; mode=display">\inf_{x \in X} f(x, \bar{y}) = \sup_{y \in Y} \inf_{x \in X} f(x, y),</script>

<p>and equality holds in minimax.  Then we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\sup_{y \in Y} \inf_{x \in X} f(x,y) &= \inf_{x \in X} f(x, \bar{y}) \\
&\leq f(\bar{x}, \bar{y}) \\
&\leq \sup_{y \in Y} f(\bar{x}, y) \\
&= \inf_{x \in X} \sup_{y \in Y} f(x, y) \\
&= \sup_{y \in Y} \inf_{x \in X} f(x,y),
\end{aligned} %]]></script>

<p>so equality holds throughout.  In particular,</p>

<script type="math/tex; mode=display">\sup_{y \in Y} f(\bar{x}, y) = f(\bar{x}, \bar{y}) = \inf_{x \in X} f(x, \bar{y}),</script>

<p>which means <script type="math/tex">(\bar{x}, \bar{y})</script> is a saddle point.</p>

<h3 id="lagrangian-saddle-points-and-the-kkt-conditions">Lagrangian saddle points and the KKT conditions</h3>
<p>When <script type="math/tex">f</script> is the Lagrangian, the saddle point theorem characterizes strong duality.  Suppose the primal optimum is attained at <script type="math/tex">\bar{x}</script> and dual optimum is attained at <script type="math/tex">\bar{y}</script>.  Then strong duality holds if and only if <script type="math/tex">(\bar{x}, \bar{y})</script> is a saddle point of the Lagrangian.</p>

<p>The point <script type="math/tex">(\bar{x}, \bar{y})</script> is a saddle point of the Lagrangian <script type="math/tex">L</script> if:</p>

<ol>
  <li>
    <script type="math/tex; mode=display">\bar{x} \in X</script>
  </li>
  <li>
    <script type="math/tex; mode=display">\bar{y} \in Y</script>
  </li>
  <li>
    <script type="math/tex; mode=display">\sup_{y \in Y} L(\bar{x}, y) = L(\bar{x}, \bar{y})</script>
  </li>
  <li>
    <script type="math/tex; mode=display">L(\bar{x}, \bar{y}) = \inf_{x \in X} L(x, \bar{y}).</script>
  </li>
</ol>

<p>In this case, strong duality holds and <script type="math/tex">(\bar{x}, \bar{y})</script> form a primal-dual optimal pair.  These saddle point conditions can be stated more explicitly as:</p>

<ol>
  <li>(Primal feasibility) <script type="math/tex">\bar{x} \in X \iff \bar{x} \in E \text{ and } g(\bar{x}) \leq 0</script></li>
  <li>(Dual feasibility) <script type="math/tex">\bar{y} \in Y \iff \bar{y} \geq 0</script></li>
  <li>(Complimentarity) <script type="math/tex">\sup_{y \in Y} L(\bar{x}, y) = L(\bar{x}, \bar{y}) \iff g(\bar{x}) \bar{y} = 0</script></li>
  <li>(Stationarity) <script type="math/tex">% <![CDATA[
L(\bar{x}, \bar{y}) = \inf_{x \in X} L(x, \bar{y})\begin{matrix} \implies& \nabla f(\bar{x}) + \sum_{i=1}^p \bar{\lambda}_i \nabla g_i(\bar{x}) = 0 \text{ (smooth problem)} \\ \iff& \nabla f(\bar{x}) + \sum_{i=1}^p \bar{\lambda}_i \nabla g_i(\bar{x}) = 0 \text{ (smooth convex problem)}  \end{matrix} %]]></script></li>
</ol>

<p>In this explicit form, the saddle point conditions are called KKT conditions.  The KKT conditions have other interpretations, as well.</p>

<h2 id="normal-cones">Normal cones</h2>

<p>Just as optimality in unconstrained smooth optimization can be characterized by a vanishing gradient, optimality in constrained optimization can be characterized by normality conditions.</p>

<p>As a simple example, consider the linearly constrained smooth problem:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\inf_{x \in E} &\quad f(x) \\
\text{subject to} &\quad Ax = 0.
\end{aligned} %]]></script>

<p>Geometrically we are minimizing the smooth function <script type="math/tex">f</script> over the hyperplane <script type="math/tex">\{ x : Ax = 0 \}</script>.  At optimality <script type="math/tex">\bar{x}</script>, the negative gradient <script type="math/tex">-\nabla f(\bar{x})</script> must be orthogonal to the hyperplane, i.e., belong to the row space of <script type="math/tex">A</script>.  Otherwise, we could move in the component of the negative gradient that lies in the hyperplane and reduce the objective while staying feasible.</p>

<p>To generalize the learnings from this simple linear example, we first need to discuss the tangent and normal cones.  These cones generalize orthogonal subspaces from linear algebra and tangent/normal spaces from smooth analysis.</p>

<h3 id="tangent-cone">Tangent cone</h3>
<p>Given a set <script type="math/tex">C</script>, the (limiting) tangent cone to <script type="math/tex">C</script> at a point <script type="math/tex">x_0 \in C</script> is defined as</p>

<script type="math/tex; mode=display">T_C(x_0) = \{ z : \text{ there exists } t_n > 0 \text{ with } t_n \to \infty \text{ and } x_n \in C \text{ with } x_n \to x_0 \text{ such that } z = t_n (x_n - x_0) \}.</script>

<p>The tangent cone is a generalization of the tangent space, which is only defined at points where the boundary is smooth.  For a convex set, the tangent cone is more simply expressed as</p>

<script type="math/tex; mode=display">T_C(x_0) = \overline{\mathbb{R_+} (C - x_0)} = \overline{ \{ t (x - x_n) : t > 0 \text{ and } x \in C \} },</script>

<p>where the bar denotes set closure.</p>

<p>The polar of the tangent cone is called normal cone:</p>

<script type="math/tex; mode=display">N_C(x_0) = \{ z : z^T x \leq 0 \text{ for all } x \in T_C(x_0) \}.</script>

<p>For a convex set, the normal cone can be written as</p>

<script type="math/tex; mode=display">N_C(x_0) = \{ z : z^T (x-x_0) \leq 0 \text{ for all } x \in C \},</script>

<p>i.e., the set of all vectors that make obtuse angle to <script type="math/tex">C</script> at <script type="math/tex">x_0</script>.  This is illustrated at two points in the figure below.</p>

<p><img src="/assets/img/normal_cone.png" alt="" /></p>

<p>The normal cone is important for characterizing optimality in convex optimization: a point <script type="math/tex">\bar{x}</script> is optimal for the problem <script type="math/tex">\min \{ f(x) : x \in C \}</script> if and only if <script type="math/tex">-\nabla f(\bar{x}) \in N_C(\bar{x})</script>.  Indeed, if <script type="math/tex">-\nabla f(\bar{x})</script> were not in the normal cone, we could find <script type="math/tex">x \in C</script> such that <script type="math/tex">-\nabla f(\bar{x})^T (x - \bar{x}) > 0</script>.  This means that <script type="math/tex">d = x-\bar{x}</script> is a descent direction for <script type="math/tex">f</script> and moving in this direction maintains feasibibility.</p>

<p>The optimality condition <script type="math/tex">-\nabla f(\bar{x}) \in N_C(\bar{x})</script> is equivalent to the KKT conditions. (With the Lagrange multipliers giving the representation of <script type="math/tex">-\nabla f(\bar{x})</script> in the normal cone.)  This is because for a convex set described by smooth inequalities <script type="math/tex">g_1 \leq 0, \ldots, g_p \leq 0</script>, the normal cone at <script type="math/tex">x</script> is the cone generated by the gradients of the active constraints:</p>

<script type="math/tex; mode=display">N_C(x) = \left\{ \sum_{i=1}^p \lambda_i \nabla g_i(x) : \lambda_i \geq 0, \ g_i(x) \lambda_i = 0 \right\}.</script>

<h2 id="convex-congugates">Convex congugates</h2>

<p>Given a function <script type="math/tex">f : \mathbb{R}^n \to \mathbb{R}</script>, the <em>convex conjugate</em> is defined by</p>

<script type="math/tex; mode=display">f^*(w) = \sup_{x \in \mathbb{R}^n} w^T x - f(x).</script>

<p>The function <script type="math/tex">f^*</script> is convex, even if <script type="math/tex">f</script> is not (since it is the pointwise maximum of convex functions).</p>

<p>Notice that <script type="math/tex">f^*(w)</script> is the is the smallest offset <script type="math/tex">b</script> so that <script type="math/tex">l(x) = w^T x - b</script> globally underestimates <script type="math/tex">f</script>.  Geometrically this defines a nonvertical supporting hyperplane <script type="math/tex">H_w = \{ (x,y) : y = w^T x - f^*(w) \}</script> to the graph of <script type="math/tex">f</script> that intersects the vertical axis at <script type="math/tex">-f^*(w)</script>.</p>

<p><img src="/assets/img/convex-conjugate.png" alt="" /></p>

<p>Also note that <script type="math/tex">f^*(w)</script> is the maximum value of the linear functional <script type="math/tex">(x, y) \mapsto (w, -1)^T (x,y)</script> over the graph of <script type="math/tex">f</script>, and so <script type="math/tex">(w,-1)</script> is normal to the graph of <script type="math/tex">f</script> where the hyperplane <script type="math/tex">H_w</script> touches:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
f^*(w) &= \sup_{x \in \mathbb{R}^n} w^T x - f(x) \\
&= \sup_{x \in \mathbb{R}^n} (w, -1)^T (x, f(x)) \\
&= \sup_{(x,y) \in \text{grh}(f)} (w, -1)^T (x,y).
\end{aligned} %]]></script>

<p>We can replace the graph with the epigraph since</p>

<script type="math/tex; mode=display">\sup_{(x,y) \in \text{grh}(f)} (w, -1)^T (x,y) = \sup_{(x,t) \in \text{epi}(f)} (w, -1)^T (x,t).</script>

<p>(Recall that the graph of a function is the set <script type="math/tex">\text{grh}(f) = \{ (x, y) : x \in \mathbb{R}^n, y = f(x) \}</script> and the epigraph is the region “above” the graph <script type="math/tex">\text{epi}(f) = \{ (x, t) : x \in \mathbb{R}^n, t \geq f(x) \}</script>.)</p>

<p>There is thus a correspondence between the domain of <script type="math/tex">f^*</script> and supporting hyperplanes to the epigraph of <script type="math/tex">f</script>.</p>

<h3 id="biconjugate">Biconjugate</h3>

<p>A “dual” view of <script type="math/tex">f</script> is given by the pointwise maximum of all linear underestimators:</p>

<script type="math/tex; mode=display">\phi(x) = \sup \{ l(x) : l \text{ is a linear underestimator of f} \}.</script>

<p>In fact, if <script type="math/tex">f</script> is closed and convex, then <script type="math/tex">\phi = f^{**}</script>, the <em>biconjugate</em> of f.  Geometrically it is clear that</p>

<script type="math/tex; mode=display">f^{**}(0) = \sup_w -f^*(w) = \phi(0)</script>

<p>from the previous discussion, and the same geometry applies at other points.</p>

<h2 id="value-function-and-the-lagrange-dual">Value function and the Lagrange dual</h2>

<p>Consider the primal optimization problem</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\inf_{x \in E} &\quad f(x) \\
\text{subject to} &\quad g(x) \leq 0,
\end{aligned} %]]></script>

<p>where <script type="math/tex">f : E \to \mathbb{R}</script> is the objective and <script type="math/tex">g : E \to \mathbb{R}^p</script> are contraint functions.  The value function describes how the optimal value changes as constraints are relaxed:</p>

<script type="math/tex; mode=display">v(b) = \inf \{ f(x) : x \in E,\ g(x) \leq b\}.</script>

<p>The conjugate of the value function closely related to the Lagrange dual:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
v^*(w) &= \sup_{b \in \mathbb{R}^p} \left\{ w^T b - v(b) \right\} \\
& = \sup_{b \in \mathbb{R}^p,\ x \in E,\ g(x) \leq b} \left\{ w^T b - f(x) \right\} \\
& = \sup_{s \geq 0,\ x \in E} \left\{ w^T (g(x) + s) - f(x) \right\} \\
& = \sup_{x \in E} \left\{ w^T g(x) - f(x) \right\} + \sup_{s \geq 0} w^T s \\
&= -\inf_{x \in E} \left\{ f(x) + (-w)^T g(x) \right\} + \sup_{s \geq 0} w^T s \\
&= \left\{ \begin{matrix} -\Pi(-w) &\quad w \leq 0 \\ \infty &\quad \text{otherwise} \end{matrix} \right. \\
&= -\Pi(-w).
\end{aligned} %]]></script>

<p>The above relation shows that the Lagrange dual problem can be viewed as maximization over supporting hyperplanes to the value function.  From previous discussions, it is clear that <script type="math/tex">v^{**}(0)</script> is the dual optimal value and <script type="math/tex">v(0)</script> is the primal optimal value.  The dual optimal vectors are subgradients to the value function at 0 and therefore contain information about how sensitive the optimal value is to the constraints.</p>

<p><img src="/assets/img/nonconvex-duality-gap.png" alt="" /></p>

<p>The figure above shows a duality gap (<script type="math/tex">p^* > d^*</script>) for the original problem <script type="math/tex">v(0)</script>.  Some of the peturbed problems <script type="math/tex">v(t)</script> have duality gaps (red regions) and others do not (green regions).</p>

<p>There is no duality gap if <script type="math/tex">v</script> has a nonvertical supporting hyperplane at 0.  This is true when <script type="math/tex">f</script> and each component of <script type="math/tex">g</script> is convex and <em>Slater’s condition</em> holds: there is a point <script type="math/tex">x</script> so that <script type="math/tex">% <![CDATA[
g(x) < 0 %]]></script>.  Convexity is not sufficient to ensure no duality gap; the function <script type="math/tex">v</script> must also be closed at 0 (see the figure below).</p>

<p><img src="/assets/img/convex-duality-gap.png" alt="" /></p>

<p>The value function above corresponds to the following convex program (which fails Slater’s condition):</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\inf_{x, y > 0} &\quad e^{-x} \\
\text{subject to} &\quad x^2 / y \leq 0.
\end{aligned} %]]></script>

<h1 id="fenchel-duality">Fenchel duality</h1>

<p>Fenchel duality consists of the primal problem</p>

<script type="math/tex; mode=display">\inf_x \{ f(x) + g(Ax) \}</script>

<p>and the dual problem</p>

<script type="math/tex; mode=display">\sup_w \{ -f^*(A^Tw) - g^*(-w) \}.</script>

<p>Duality is analyzed through the perturbation function <script type="math/tex">v(u) = \inf_x \{ f(x) + g(Ax - u) \}</script>, which is convex in <script type="math/tex">u</script>.</p>

<p>Notice that the primal optimal value is <script type="math/tex">v(0)</script>, and the dual problem is <script type="math/tex">\max_w -v^*(w) = v^{**}(0)</script> since:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
-v^*(w) &= \inf_u \{ v(u) - w^T u \} \\
&= \inf_{u,x} \{ f(x) + g(Ax-u) - w^Tu \} \\
&= \inf_{z,x} \{ f(x) + g(z) - w^T(Ax - z) \} \\
&= \inf_{z,x} \{ f(x) - (A^Tw)^T x + g(z) - (-w)^T z \} \\
&= -f^*(A^T w) - g^*(-w).
\end{aligned} %]]></script>

<p>Strong duality holds when 0 belongs to the interior of the domain of <script type="math/tex">v</script> (recall the domain of convex function is the region where it is not positive infinity).  Further note that:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
u \in \text{dom} (v) &\iff \exists  x \text{ s.t } f(x) + g(Ax - u) < \infty \\
&\iff \exists  x \text{ s.t } x \in \text{dom}(f) \text{ and } Ax - u \in \text{dom}(g) \\
&\iff u \in A \text{dom}(f) - \text{dom}(g),
\end{aligned} %]]></script>

<p>so <script type="math/tex">\text{dom}(v) = A \text{dom}(f) - \text{dom}(g)</script>, and strong duality holds if <script type="math/tex">0 \in \text{int}(A \text{dom}(f) - \text{dom}(g))</script>.</p>

<h1 id="duality-via-perturbation-functions">Duality via perturbation functions</h1>

<p>We derived both Lagrangian and Fenchel duality by reasoning about perturbations.  More generally a perturbation function <script type="math/tex">F(x,u)</script> is one where <script type="math/tex">f(x) = F(x,0)</script>.  By considering</p>

<script type="math/tex; mode=display">v(u) = \inf_x F(x, u)</script>

<p>and its conjugate</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
-v^*(w) &= \inf_u \{ v(u) - w^T u \} \\
&= \inf_{x,u} \{ F(x,u) - w^T u \} \\
&= \inf_{x,u} \{ F(x,u) - (0,w)^T (x,u) \} \\
&= -F^*(0,w)
\end{aligned} %]]></script>

<p>we get the primal problem</p>

<script type="math/tex; mode=display">\inf_x F(x,0)</script>

<p>and the dual problem</p>

<script type="math/tex; mode=display">\sup_w -F^*(0,w).</script>

<h1 id="references">References</h1>

<ul>
  <li><em>Convex analysis and nonlinear optimization</em> by Borwein and Lewis</li>
  <li><em>Convex optimization</em> by Boyd and Vandenberghe</li>
  <li><em>Convex analysis</em> by Rockafellar</li>
  <li><em>Variational analysis</em> by Rockafellar and Wets</li>
</ul>



<span class="post-date">
  Written on
  
  August
  16th,
  2020
  by
  
    Scott Roy
  
</span>

<div class="post-date">Feel free to share!</div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=Optimization and duality&amp;url=/optimization-duality.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=/optimization-duality.html&amp;title=Optimization and duality" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
    <a href="https://plus.google.com/share?url=/optimization-duality.html" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
  </div>
</div>


<div class="related">
  <h1 >You may also enjoy:</h1>
  
  <ul class="related-posts">
    
  </ul>
</div>




    </div>

    <footer class="footer">
  
  
  
    <a href="https://www.github.com/scottroy" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/scott-roy/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:scott.michael.roy@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  <div class="post-date"><a href="/menu/about.html">statsandstuff | a blog on statistics and machine learning by Scott Roy</a></div>
</footer>

  </div>

</body>
</html>
