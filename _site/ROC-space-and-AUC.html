<!doctype html>
<html>

<head>

  <title>
    
      ROC space and AUC | statsandstuff
    
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/syntax.css">
  <!-- Use Atom -->
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="statsandstuff" />
  <!-- Use RSS-2.0 -->
  <!--<link href="/rss-feed.xml" type="application/rss+xml" rel="alternate" title="statsandstuff | a blog on statistics and machine learning"/>
  //-->

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-135466463-1', 'auto');
  ga('send', 'pageview');
</script>


<meta name="author" content="Scott Roy"/>  
<meta property="og:locale" content="en_US">
<meta property="og:description" content="KEVIN WAS HERE Before discussing ROC curves and AUC, let’s fix some terminology around the confusion matrix: Condition positive (negative): real positive (negative) case in the data True positive (negative):...">
<meta property="description" content="KEVIN WAS HERE Before discussing ROC curves and AUC, let’s fix some terminology around the confusion matrix: Condition positive (negative): real positive (negative) case in the data True positive (negative):...">
<meta property="og:title" content="ROC space and AUC">
<meta property="og:site_name" content="statsandstuff">
<meta property="og:type" content="article">
<meta property="og:url" content="http://localhost:4000/ROC-space-and-AUC.html">
<meta property="og:image:url" content="http://localhost:4000/assets/img/cost_roc_space.png">
<meta property="og:image:secure_url" content="http://localhost:4000/assets/img/cost_roc_space.png">
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />



</head>


<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="/">statsandstuff</a>
    <small class="masthead-subtitle">a blog on statistics and machine learning</small>
    <div class="menu">
  <nav class="menu-content">
    
      <a href="/menu/about.html">About</a>
    
      <a href="/menu/writing.html">Writing</a>
    
      <a href="/menu/contact.html">Contact</a>
    
  </nav>
  <nav class="social-icons">
    
  
  
    <a href="https://www.github.com/scottroy" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/scott-roy/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:scott.michael.roy@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  </nav>
</div>

  </h3>
</header>


    <div class="post-container">
      <h1>
  ROC space and AUC
</h1>


  <img src="/assets/img/cost_roc_space.png">


<h1 id="kevin-was-here">KEVIN WAS HERE</h1>

<p>Before discussing ROC curves and AUC, let’s fix some terminology around the confusion matrix:</p>

<ul>
  <li><strong>Condition positive (negative):</strong> real positive (negative) case in the data</li>
  <li><strong>True positive (negative):</strong> condition positive (negative) that is classified as positive (negative)</li>
  <li><strong>False positive (negative):</strong> condition negative (positive) that is classified as positive (negative)</li>
  <li><strong>True positive rate (TPR):</strong> empirically defined as (# true positives) / (# condition positives).  More generally, it is the probability that a condition positive is labelled as positive.</li>
  <li><strong>False positive rate (FPR):</strong> empirically defined as (# false positives) / (# condition negatives).  More generally, it is the probability that a condition negative is classified as positive.</li>
</ul>

<p><img src="/assets/img/confusion.png" alt="" /></p>

<p>True positive rate and false positive rate do not depend on the class ratio, that is, the ratio of condition positives to condition negatives in the data. Contrast this with precision, the number of true positives over the number of predicted positives, which does depend on the class ratio.</p>

<h2 id="roc-space">ROC Space</h2>

<p>The concept of ROC (receiver operator characteristic) space was introduced by engineers during WWII.  Radar operators had to decide if a blip on a radar screen was an enemy target or not. The performance of different operators can be compared by plotting an operator’s true positive rate along the y-axis and false positive rate along the x-axis.</p>

<p><img src="/assets/img/random_guessers.png" alt="" /></p>

<p>In “ROC space,” the better operators are in the upper, left corner (high true positive rate, low false positive rate). Any decent operator lies in the upper, left region above the diagonal. In fact, points on the diagonal correspond to the performance of “random guessers.” Suppose Jim flips a coin and classifies a blip as an enemy target if the coin shows heads. In this case, Jim will classify half of condition positives as targets (50% true positive rate) and half of condition negatives as targets (50% false positive rate). If the coin is biased and has a 70% chance of showing heads, Jim’s TPR and FPR will both be 70%. The entire diagonal line corresponds to the performance of random guessers who use biased coins with varying probabilities of showing heads.</p>

<h2 id="roc-curves">ROC Curves</h2>
<p>Like radar operators, we can compare the performance of classifiers by plotting TPR and FPR in ROC space. Before discussing ROC curves, I want to distinguish between a classifier and a scorer. A classifier labels an input as positive or negative. Its output is binary. Many classifiers in machine learning are built from scorers. A scorer assigns each input a score that measures a “belief” that the input is a positive example. For example, a logistic regression scorer assigns each input a probability score of being a positive example. (As an aside, the probability scores computed by logistic regression (or any machine learning model) need not be well-calibrated, true probabilities. For this reason, care should be taken when comparing scores from different models.)  We get a logistic regression classifier, for example, by labelling an input as positive if its score is greater than 0.5.  A scorer generates many classifiers indexed by a threshold <script type="math/tex">t</script>, where the classifier at threshold <script type="math/tex">t</script> labels an input as positive or negative depending on if its score is above or below <script type="math/tex">t</script>.</p>

<p>We can plot the performance of all the classifiers generated by a scorer in ROC space.  For high values of <script type="math/tex">t</script>, few examples are classified as positive, and so both the true positive rate and false positive rate are low. Similarly, the true positive rate and false positive rate are are high for low values of <script type="math/tex">t</script>.  So the ROC curve for a scorer starts in the upper right corner, ends in the lower left corner, and will (hopefully) bulge out toward the upper left corner.</p>

<h2 id="auc">AUC</h2>
<p>A good scorer will have an ROC curve that bulges out toward the upper left corner.  The AUC is the area under the ROC curve, and is a heuristic for measuring how much the curve bulges toward the upper left corner.  A perfect scorer has AUC 1.</p>

<p>AUC has an alternative interpretation: it is the probability that a condition positive has a higher score than a condition negative.  Let’s see why. Let <script type="math/tex">\beta(t)</script> be the TPR at threshold <script type="math/tex">t</script> and <script type="math/tex">\alpha(t)</script> be the FPR at threshold <script type="math/tex">t</script>. (Notice that the use of <script type="math/tex">\alpha</script> and <script type="math/tex">\beta</script> here is consistent with their use to denote Type I error and power in statistics.)
Let <script type="math/tex">f_{+}(x)</script> be the score density of the condition positives.  Then we can write <script type="math/tex">\beta(t) = \int_{t}^{\infty} f_{+}(x)\ dx</script>. Similarly, <script type="math/tex">\alpha(t) = \int_t^{\infty} f_{-}(x) \ dx</script>.  The AUC is the integral over infinitesimal rectangles under of the ROC curve. The rectangle at <script type="math/tex">\alpha</script> has height <script type="math/tex">\beta(t)</script> and width <script type="math/tex">d\alpha = f_{-}(t) dt</script>.</p>

<p><img src="/assets/img/auc.png" alt="" /></p>

<p>Putting things together, we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}\text{AUC} &= \int \beta(t) f_{-}(t) dt \\ &= \int \textbf{P}(\text{condition positive has score greater than } t)\ \textbf{P}(\text{condition negative has score } t) dt \\ &= \textbf{P}(\text{condition positive has higher score than condition negative}). \end{aligned} %]]></script>

<p>ROC curves and AUC (being based on TPR and FPR) do not depend on the class ratio in the data.</p>

<h2 id="picking-the-best-classifier-in-roc-space">Picking the “best” classifier in ROC space</h2>
<p>A classifier above <strong>and</strong> to the left of another in ROC space is objectively better.  But not all points in ROC space are comparable.</p>

<p><img src="/assets/img/better_worse_roc_space.png" alt="" /></p>

<p>For example, a classifier can have a better TPR than another, but a worse FPR.  Choosing between incomparable classifiers depends on the specific problem.  In particular, it depends on the cost of a false positive, the cost of a false negative, and the ratio of condition positives to condition negatives in the data.  As an example, consider a classifier that predicts if a patient has HIV.  In this case, the cost of a false negative (failing to detect an HIV positive patient) is significantly more than the cost of a false positive (incorrectly diagnosing HIV).</p>

<p>Let’s model expected total cost.  Each mistake has a cost.  Let <script type="math/tex">M_{+}</script> be the number of false positives and <script type="math/tex">c_{+}</script> be the cost of a false positive (with similar definitions for <script type="math/tex">M_{-}</script> and <script type="math/tex">c_{-}</script>).  In expectation, <script type="math/tex">M_{+}</script> is <script type="math/tex">n p_{-} \alpha</script>, where <script type="math/tex">n</script> is the number of classified points, <script type="math/tex">p_{-}</script> is the probability of a condition negative, and <script type="math/tex">\alpha</script> is the true positive rate.  Similarly, the expected value of <script type="math/tex">M_{-}</script> is <script type="math/tex">n p_{+} (1-\beta)</script>.  The average total cost is</p>

<script type="math/tex; mode=display">c_{+} n p_{-} \alpha + c_{-} n p_{+} (1-\beta),</script>

<p>and we can find the best classifier by minimizing this over ROC space.  Equivalently, we can maximize the linear functional</p>

<script type="math/tex; mode=display">(\alpha, \beta) \mapsto -\left( \frac{c_{+}}{c_{-}} \right) \left( \frac{p_{-}}{p_{+}} \right) \alpha + \beta.</script>

<p>Notice that the selection of the best classifier only depends on the cost ratio <script type="math/tex">c_{+} / c_{-}</script> and the class ratio <script type="math/tex">p_{-} / p_{+}</script>. In the special case where the classes are balanced and a false positive has the same cost as a false negative, the best classifier is the one furthest in the northeast direction.</p>

<p><img src="/assets/img/cost_roc_space.png" alt="" /></p>

<h2 id="interpolating-classifiers-in-roc-space">Interpolating classifiers in ROC space</h2>
<p>Given any two classifiers in ROC space, we can interpolate on the line segment between them.  Suppose classifier 1 is at <script type="math/tex">(\alpha_1, \beta_1)</script> and classifier 2 is at <script type="math/tex">(\alpha_2, \beta_2)</script>.  We can form a combined classifier that lies at <script type="math/tex">(\theta \alpha_1 + (1-\theta) \alpha_2, \theta \beta_1 + (1-\theta) \beta_2)</script> as follows.  We flip a coin that shows heads with probability <script type="math/tex">\theta</script> and predict the output of classifier 1 if the coin shows heads, and predict the output of classifier 2 if the coin shows tails. In this way, we can get the performance of any point in the convex hull of the classifiers we plot in ROC space.</p>

<h2 id="references">References</h2>
<ul>
  <li><em>Measuring classifier performance: a coherent alternative to the area under the ROC curve</em> by David J. Hand</li>
  <li><em>An introduction to ROC analysis</em> by Tom Fawcett</li>
</ul>


<span class="post-date">
  Written on
  
  April
  29th,
  2018
  by
  
    Scott Roy
  
</span>

<div class="post-date">Feel free to share!</div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=ROC space and AUC&amp;url=/ROC-space-and-AUC.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=/ROC-space-and-AUC.html&amp;title=ROC space and AUC" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
    <a href="https://plus.google.com/share?url=/ROC-space-and-AUC.html" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
  </div>
</div>


<div class="related">
  <h1 >You may also enjoy:</h1>
  
  <ul class="related-posts">
    
      
        
          <li>
            <h3>
              <a href="/what-makes-a-better-score-distribution.html">
                What makes a better score distribution?
                <!--<img src="http://localhost:4000/images/">-->
                <!--<small>September 29, 2019</small>-->
              </a>
            </h3>
          </li>
          
        
      
        
        
      
    
      
        
        
      
    
      
        
        
      
    
      
        
        
      
    
      
        
          <li>
            <h3>
              <a href="/controlling-error-when-testing-many-hypotheses.html">
                Controlling error when testing many hypotheses
                <!--<img src="http://localhost:4000/images/">-->
                <!--<small>November 18, 2018</small>-->
              </a>
            </h3>
          </li>
          
        
      
        
        
      
        
          <li>
            <h3>
              <a href="/multiple-hypothesis-tests.html">
                Multiple Hypothesis Tests
                <!--<img src="http://localhost:4000/images/">-->
                <!--<small>April 13, 2018</small>-->
              </a>
            </h3>
          </li>
          
        
      
    
      
        
        
      
        
        
      
        
        
      
    
  </ul>
</div>




    </div>

    <footer class="footer">
  
  
  
    <a href="https://www.github.com/scottroy" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://www.linkedin.com/in/scott-roy/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:scott.michael.roy@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  <div class="post-date"><a href="/menu/about.html">statsandstuff | a blog on statistics and machine learning by Scott Roy</a></div>
</footer>

  </div>

</body>
</html>
